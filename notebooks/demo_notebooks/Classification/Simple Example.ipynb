{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Test data:\n",
    "\n",
    "Define a data folder which will contain\n",
    "* Training data files (tif format)\n",
    "* Test data files (tif format)\n",
    "* Ground truth file (shapefile)\n",
    "\n",
    "For demenstarion purpose we created example files to be used in this notebook: training: train1.tif, train2.tif test files: test.tif, ground truth: OudeKerk_final4.shp\n",
    "\n",
    "### Creating your own shapefile\n",
    "If you want to create your own shapefile, this can be done via the open source desktop GIS: QGIS  https://qgis.org/en/site/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/yifat/satsense/notebooks/demo_notebooks/Classification', '/home/yifat/anaconda3/envs/satsense/lib/python37.zip', '/home/yifat/anaconda3/envs/satsense/lib/python3.7', '/home/yifat/anaconda3/envs/satsense/lib/python3.7/lib-dynload', '', '/home/yifat/anaconda3/envs/satsense/lib/python3.7/site-packages', '/home/yifat/anaconda3/envs/satsense/lib/python3.7/site-packages/IPython/extensions', '/home/yifat/.ipython']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.path)\n",
    "#import satsense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "sampling_step_size = 10, 10\n",
    "\n",
    "windows = (\n",
    "    (50, 50),\n",
    "    (100, 100),\n",
    "    (200, 200),\n",
    ")\n",
    "\n",
    "home = Path.home()\n",
    "data = home / 'satsense' / 'test' / 'data' / 'source'\n",
    "\n",
    "train_files = (\n",
    "      data / 'train1.tif',\n",
    "      data / 'train2.tif'\n",
    ")\n",
    "\n",
    "test_files = (\n",
    "    data / 'test.tif',\n",
    ")\n",
    "\n",
    "ground_truth_file = data / 'OudeKerk_final4.shp'\n",
    "\n",
    "# Path where temporary files are saved\n",
    "work = home / 'satsense_notebook'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the set of features for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from satsense.features import (NirNDVI, HistogramOfGradients, Pantex, Sift,\n",
    "                               Lacunarity, Texton)\n",
    "from satsense import Image\n",
    "train_images = [Image(file, 'RGB') for file in train_files]\n",
    "\n",
    "ndvi = NirNDVI(windows) #vegetation\n",
    "#hog = HistogramOfGradients(windows) \n",
    "#pantex = Pantex(windows) \n",
    "#lacunarity = Lacunarity(windows)\n",
    "sift = Sift.from_images(windows, train_images)\n",
    "#texton = Texton.from_images(windows, train_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    ndvi,\n",
    "#    hog,\n",
    "#    pantex,\n",
    "#    lacunarity,\n",
    "    sift,\n",
    "#    texton,\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute and save features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from satsense import extract_features\n",
    "from satsense.generators import FullGenerator\n",
    "\n",
    "def compute_features(filenames):\n",
    "    paths = []\n",
    "    for filename in filenames:\n",
    "        image = Image(filename, 'RGB')\n",
    "        path = str(work / Path(filename).stem) + os.sep\n",
    "        paths.append(path)        \n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "            generator = FullGenerator(image, sampling_step_size)\n",
    "            for feature_vector in extract_features(features, generator, n_jobs = 1):\n",
    "                print(feature_vector)\n",
    "                feature_vector.save(path)\n",
    "    return paths\n",
    "        \n",
    "train_data_paths = compute_features(train_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load training data\n",
    "\n",
    "The ShapeFile is using the following faturesL buildings, natural, landuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /home/yifat/satsense/test/data/source/train1.tif\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Could not find a file containing feature NirNDVI in /home/yifat/satsense_notebook/train1/",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-8c46f4f970a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Processing\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;31m# Load feature vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mfeature_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_feature_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mlabel_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_vector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-86-8c46f4f970a6>\u001b[0m in \u001b[0;36mload_feature_vector\u001b[0;34m(features, path)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mfeature_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mvector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFeatureVector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;31m# flatten window/feature_size dimensions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mvector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/satsense/lib/python3.7/site-packages/satsense/image.py\u001b[0m in \u001b[0;36mfrom_file\u001b[0;34m(cls, feature, filename_prefix)\u001b[0m\n\u001b[1;32m    347\u001b[0m                 raise ValueError(\n\u001b[1;32m    348\u001b[0m                     \"Could not find a file containing feature {} in {}\".format(\n\u001b[0;32m--> 349\u001b[0;31m                         feature.name, filename_prefix))\n\u001b[0m\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuffix\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'.nc'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Could not find a file containing feature NirNDVI in /home/yifat/satsense_notebook/train1/"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from satsense import Image, FeatureVector\n",
    "from satsense.util.mask import get_ndxi_mask, load_mask_from_shapefile, resample, save_mask2file\n",
    "from satsense.features import NirNDVI, WVSI\n",
    "from satsense.generators import FullGenerator\n",
    "\n",
    "def load_feature_vector(features, path):\n",
    "    \"\"\"Load feature values from file.\"\"\"\n",
    "    feature_vector = []\n",
    "    for feature in features:\n",
    "        vector = FeatureVector.from_file(feature, path).vector\n",
    "        # flatten window/feature_size dimensions\n",
    "        vector.shape = (vector.shape[0], vector.shape[1], -1)\n",
    "        feature_vector.append(vector)\n",
    "    feature_vector = np.ma.dstack(feature_vector)\n",
    "    return feature_vector\n",
    "\n",
    "def load_ground_truth(filename, sampling_step_size, path, shape, crs, transform):\n",
    "    ground_truth = load_mask_from_shapefile(filename, shape, transform)\n",
    "    mask_file = os.path.join(path, 'ground_truth_mask.tif')\n",
    "    ground_truth_mask = save_mask2file(ground_truth, mask_file, crs, transform)\n",
    "    ground_truth_image = Image(mask_file, 'monochrome', normalization_parameters=False)\n",
    "    ground_truth = resample(FullGenerator(ground_truth_image, sampling_step_size))\n",
    "    return ground_truth\n",
    "\n",
    "labels = {\n",
    "    'buildings': 0,\n",
    "    'landuse': 1,\n",
    "    'natural': 2,\n",
    "}\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for path, image in zip(train_data_paths, train_images):\n",
    "    print(\"Processing\", image.filename)\n",
    "    # Load feature vector\n",
    "    feature_vector = load_feature_vector(features, path)\n",
    "    \n",
    "    label_vector = np.zeros(feature_vector.shape[:2], dtype=np.uint8)\n",
    "\n",
    "    # Create deprived neighbourhood labels\n",
    "    ground_truth = load_ground_truth(\n",
    "        ground_truth_file, sampling_step_size, path, image.shape, image.crs, image.transform)\n",
    "    label_vector[ground_truth] = labels['buildings']\n",
    "\n",
    "    # Create vegetation labels\n",
    "    #generator = FullGenerator(image, sampling_step_size)\n",
    "    #vegetation_mask = get_ndxi_mask(generator, NirNDVI)\n",
    "    #label_vector[vegetation_mask] = labels['vegetation']\n",
    "\n",
    "    # Create x_train and y_train\n",
    "    feature_vector.shape = (-1, feature_vector.shape[2])\n",
    "    label_vector.shape = (-1, )\n",
    "\n",
    "    x_train.append(feature_vector)\n",
    "    y_train.append(label_vector)\n",
    "    \n",
    "x_train = np.concatenate(x_train)\n",
    "y_train = np.concatenate(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yifat/anaconda3/envs/satsense/lib/python3.7/site-packages/numpy/core/_methods.py:36: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "y contains 1 class after sample_weight trimmed classes with zero weights, while a minimum of 2 classes are required.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-1285a7487ed7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGradientBoostingClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/satsense/lib/python3.7/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m   1402\u001b[0m         \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1404\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter_no_change\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/satsense/lib/python3.7/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36m_validate_y\u001b[0;34m(self, y, sample_weight)\u001b[0m\n\u001b[1;32m   1967\u001b[0m                              \u001b[0;34m\"trimmed classes with zero weights, while a \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1968\u001b[0m                              \u001b[0;34m\"minimum of 2 classes are required.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1969\u001b[0;31m                              % n_trim_classes)\n\u001b[0m\u001b[1;32m   1970\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_classes_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1971\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: y contains 1 class after sample_weight trimmed classes with zero weights, while a minimum of 2 classes are required."
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "classifier = GradientBoostingClassifier(verbose=True)\n",
    "    \n",
    "classifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load test data and assess performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.96921e+36 9.96921e+36 9.96921e+36 ... 9.96921e+36 9.96921e+36\n",
      "  9.96921e+36]\n",
      " [9.96921e+36 9.96921e+36 9.96921e+36 ... 9.96921e+36 9.96921e+36\n",
      "  9.96921e+36]\n",
      " [9.96921e+36 9.96921e+36 9.96921e+36 ... 9.96921e+36 9.96921e+36\n",
      "  9.96921e+36]\n",
      " ...\n",
      " [9.96921e+36 9.96921e+36 9.96921e+36 ... 9.96921e+36 9.96921e+36\n",
      "  9.96921e+36]\n",
      " [9.96921e+36 9.96921e+36 9.96921e+36 ... 9.96921e+36 9.96921e+36\n",
      "  9.96921e+36]\n",
      " [9.96921e+36 9.96921e+36 9.96921e+36 ... 9.96921e+36 9.96921e+36\n",
      "  9.96921e+36]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "band index 5 out of range (not in (1, 2, 3, 4))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-9227f5ebbe88>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatthews_corrcoef\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtest_data_paths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'worldview3'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_files\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-74b311516e77>\u001b[0m in \u001b[0;36mcompute_features\u001b[0;34m(filenames)\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mgenerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFullGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampling_step_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature_vector\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m                 \u001b[0mfeature_vector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpaths\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/satsense/lib/python3.6/site-packages/satsense/extract.py\u001b[0m in \u001b[0;36mextract_features\u001b[0;34m(features, generator, n_jobs)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m_extract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m_extract_features_parallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/satsense/lib/python3.6/site-packages/satsense/extract.py\u001b[0m in \u001b[0;36m_extract_features_parallel\u001b[0;34m(features, generator, n_jobs)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mn_jobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcpu_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Extracting features using at most %s processes\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecompute_normalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;31m# Split generator in chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/satsense/lib/python3.6/site-packages/satsense/image.py\u001b[0m in \u001b[0;36mprecompute_normalization\u001b[0;34m(self, *bands)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mband\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbands\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbands\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mband\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_normalization_limits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mband\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_normalization_limits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mband\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/satsense/lib/python3.6/site-packages/satsense/image.py\u001b[0m in \u001b[0;36m_get_normalization_limits\u001b[0;34m(self, band, image)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m                 \u001b[0moverwrite_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m                 \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_band\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mband\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m                 \u001b[0moverwrite_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/satsense/lib/python3.6/site-packages/satsense/image.py\u001b[0m in \u001b[0;36m_read_band\u001b[0;34m(self, band, block)\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrasterio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m             image = dataset.read(\n\u001b[0;32m--> 109\u001b[0;31m                 bandno, window=block, boundless=True, masked=True)\n\u001b[0m\u001b[1;32m    110\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mrasterio/_io.pyx\u001b[0m in \u001b[0;36mrasterio._io.DatasetReaderBase.read\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: band index 5 out of range (not in (1, 2, 3, 4))"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, matthews_corrcoef, confusion_matrix\n",
    "\n",
    "test_data_paths = compute_features(test_files)\n",
    "\n",
    "test_images = [Image(f, 'worldview3') for f in test_files]\n",
    "\n",
    "for path, image in zip(test_data_paths, test_images):\n",
    "    print('Performance on', image.filename)\n",
    "    # Create x_test\n",
    "    x_test = load_feature_vector(features, path)\n",
    "    shape = x_test.shape\n",
    "    x_test.shape = (-1, shape[2])\n",
    "    \n",
    "    # Predict the labels\n",
    "    y_pred = classifier.predict(x_test)\n",
    "    \n",
    "    # Create y_test\n",
    "    y_test = np.zeros(shape[:2], dtype=np.uint8)\n",
    "    \n",
    "    # Create deprived neighbourhood labels \n",
    "    ground_truth = load_ground_truth(\n",
    "        ground_truth_file, sampling_step_size, path, image.shape, image.crs, image.transform)\n",
    "    y_test[ground_truth] = labels['deprived_neighbourhood']\n",
    "\n",
    "    # Create vegetation labels\n",
    "    generator = FullGenerator(image, sampling_step_size)\n",
    "    vegetation_mask = get_ndxi_mask(generator, NirNDVI)\n",
    "    y_test[vegetation_mask] = labels['vegetation']\n",
    "    y_test.shape = (-1, )\n",
    "    \n",
    "    # Assess performance\n",
    "\n",
    "    # Label the vegetation as buildings to create more accurate representation of the performance\n",
    "    # y_pred[y_pred == labels['vegetation']] = labels['other']\n",
    "    # y_test[y_test == labels['vegetation']] = labels['other']\n",
    "\n",
    "    print(matthews_corrcoef(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred, labels=list(labels.values()), target_names=list(labels.keys())))\n",
    "    print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
